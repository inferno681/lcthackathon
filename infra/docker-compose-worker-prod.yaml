services:
  text_embeddings_inference:
    image: ghcr.io/huggingface/text-embeddings-inference:turing-1.2
    container_name: embeddings
    restart: always
    ports:
      - "8082:80"
    volumes:
      - ./data:/data
    environment:
      - MODEL_ID=intfloat/multilingual-e5-small

  ollama:
    image: ollama/ollama
    container_name: ollama
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    volumes:
      - ./data:/root/.ollama
    ports:
      - "8083:11434"
    restart: always
  whisper:
    image: fedirz/faster-whisper-server:latest-cuda
    container_name: whisper
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
    ports:
      - "8081:8000"
    volumes:
      - ./data:/root/.cache/huggingface
    environment:
      - WHISPER_MODEL=Systran/faster-whisper-base
    restart: always
  backend:
    image: inferno681/lcthackathon:latest
    restart: always
    env_file:
      - .env
    depends_on:
      - text_embeddings_inference
      - ollama
      - whisper

volumes:
  db_value:
  redis_data:
