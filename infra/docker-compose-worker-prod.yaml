services:
  text_embeddings_inference:
    image: ghcr.io/huggingface/text-embeddings-inference:turing-1.2
    container_name: embeddings
    restart: always
    ports:
      - "8082:80"
    volumes:
      - ./dataemb:/data
    environment:
      - MODEL_ID=sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  ollama:
    image: ollama/ollama
    container_name: ollama
    volumes:
      - ./data:/root/.ollama
    ports:
      - "8083:11434"
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  whisper:
    image: fedirz/faster-whisper-server:latest-cuda
    container_name: whisper
    ports:
      - "8081:8000"
    volumes:
      - ./datawhisp:/root/.cache/huggingface
    environment:
      - WHISPER_MODEL=Systran/faster-whisper-base
    restart: always
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]
  backend:
    image: inferno681/lcthackathon1:latest
    restart: always
    env_file:
      - .env
    volumes:
      - ./temp/:/temp/
    depends_on:
      - text_embeddings_inference
      - ollama
      - whisper
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: all
              capabilities: [gpu]

volumes:
  db_value:
  redis_data:
